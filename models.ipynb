{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416f6305",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa65e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Gradient boosting\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Mute warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3b0698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success                                int64\n",
       "num_degs_finished_by_curr_ceo        float64\n",
       "max_number_founded_by_one_founder    float64\n",
       "avg_num_degs_finished_by_founders      int64\n",
       "at_least_one_veteran_founder           int64\n",
       "years_between_degree_founding          int64\n",
       "years_between_first_curr_founding      int64\n",
       "Advertising                            int64\n",
       "Apps                                   int64\n",
       "Commerce and Shopping                  int64\n",
       "Community and Lifestyle                int64\n",
       "Consumer Electronics                   int64\n",
       "Content and Publishing                 int64\n",
       "Data and Analytics                     int64\n",
       "Design                                 int64\n",
       "Education                              int64\n",
       "Financial Services                     int64\n",
       "Hardware                               int64\n",
       "Health Care                            int64\n",
       "Information Technology                 int64\n",
       "Internet Services                      int64\n",
       "Manufacturing                          int64\n",
       "Media and Entertainment                int64\n",
       "Mobile                                 int64\n",
       "Other                                  int64\n",
       "Professional Services                  int64\n",
       "Real Estate                            int64\n",
       "Sales and Marketing                    int64\n",
       "Science and Engineering                int64\n",
       "Software                               int64\n",
       "Video                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First import the data\n",
    "dataset =  pd.read_csv('finished_data/finished_data.csv').drop(columns=['Unnamed: 0'])\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa54326",
   "metadata": {},
   "source": [
    "## Final data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab74981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a dataset of 67334 observations\n",
      "We have a dataset of 31 predictors\n",
      "Out of that number, we have 8443 successful companies which accounts for a 12.54% of all observations\n",
      "Out of that number, we have 58891 failed companies which accounts for a 87.46% of all observations\n"
     ]
    }
   ],
   "source": [
    "success = dataset['success'].sum()\n",
    "failure = dataset['success'].count() - success\n",
    "\n",
    "print(f'We have a dataset of {success + failure} observations')\n",
    "print(f'We have a dataset of {len(dataset.columns)} predictors')\n",
    "print(f'Out of that number, we have {success} successful companies which accounts for a {success/(success + failure)*100:.2f}% of all observations')\n",
    "print(f'Out of that number, we have {failure} failed companies which accounts for a {failure/(success + failure)*100:.2f}% of all observations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1493c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['success'])\n",
    "y = dataset['success']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8,random_state=109,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e457eae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X_train dataset is (53867, 30)\n",
      "The size of y_train dataset is (53867,)\n",
      "The size of X_test dataset is (13467, 30)\n",
      "The size of y_test dataset is (13467,)\n"
     ]
    }
   ],
   "source": [
    "print(f'The size of X_train dataset is {X_train.shape}')\n",
    "print(f'The size of y_train dataset is {y_train.shape}')\n",
    "print(f'The size of X_test dataset is {X_test.shape}')\n",
    "print(f'The size of y_test dataset is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2877ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant scores\n",
    "scores = ['accuracy','f1','precision','recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca505ea",
   "metadata": {},
   "source": [
    "## Majority classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6422a66-a1f2-40d8-8cd3-c55fc17a9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definde majority classifier model\n",
    "class majority_classifier():\n",
    "    \n",
    "    def train(self,X,y):\n",
    "        self.pred = np.bincount(y).argmax()\n",
    "    \n",
    "    def predict(self,X):\n",
    "        n = len(X)\n",
    "        return np.array(n * [self.pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d737dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "majority = majority_classifier()\n",
    "majority.train(X_train,y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred = majority.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "563988ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.8746\n",
      "F1 score = 0.0000\n",
      "Precision score = 0.0000\n",
      "Recall score = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy, precision, recall, F1\n",
    "print(f'Accuracy score = {accuracy_score(y_test,y_pred):.4f}')\n",
    "print(f'F1 score = {f1_score(y_test,y_pred):.4f}')\n",
    "print(f'Precision score = {precision_score(y_test,y_pred):.4f}')\n",
    "print(f'Recall score = {recall_score(y_test,y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a28ea",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f08879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9e6a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Initial 10-fold cross-validation) accuracy = 0.8738\n",
      "(Initial 10-fold cross-validation) f1 = 0.0153\n",
      "(Initial 10-fold cross-validation) precision = 0.3554\n",
      "(Initial 10-fold cross-validation) recall = 0.0078\n"
     ]
    }
   ],
   "source": [
    "# Initial results\n",
    "logit = LogisticRegression(penalty='none',max_iter=100*10000,solver='saga')\n",
    "\n",
    "# Cross validation\n",
    "results = cross_validate(logit,X=X_train_scaled,y=y_train,scoring=scores,cv=10)\n",
    "\n",
    "d_logit_initial = {}\n",
    "\n",
    "for i in range(4):\n",
    "    score = scores[i]\n",
    "    d_logit_initial[score] = np.mean(results['test_' + score])\n",
    "    print(f'(Initial 10-fold cross-validation) {score} = {d_logit_initial[score]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c532778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(max_iter=1000000, solver='saga'),\n",
       "             param_grid={'C': [0.01, 0.1, 0.5, 10, 50, 100],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             refit='f1', scoring=['accuracy', 'f1', 'precision', 'recall'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tunning\n",
    "\n",
    "# Get hyperparameter options\n",
    "parameters = {\n",
    "    'penalty':['l1', 'l2'], \n",
    "    'C':[0.01, 0.1, 0.5, 10, 50, 100]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "logit = LogisticRegression(max_iter=100*10000,solver='saga')\n",
    "\n",
    "# Use gridsearch to determine the best model\n",
    "model_GSCV_logit = GridSearchCV(logit,parameters,scoring=scores,cv=5,refit='f1')\n",
    "\n",
    "# fit\n",
    "model_GSCV_logit.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98f92b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  10\n",
      "penalty =  l1\n"
     ]
    }
   ],
   "source": [
    "# Print best parameters\n",
    "best_params = model_GSCV_logit.best_params_\n",
    "\n",
    "for key, value in best_params.items():\n",
    "    print(f'{key} =  {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "388ed1ba-c628-45d0-b3ae-432391b97027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GridSearchCV-tuned model) Accuracy score = 0.8736\n",
      "(GridSearchCV-tuned model) F1 score = 0.0218\n",
      "(GridSearchCV-tuned model) Precision score = 0.3725\n",
      "(GridSearchCV-tuned model) Recall score = 0.0112\n"
     ]
    }
   ],
   "source": [
    "# Get best model\n",
    "best_logit = model_GSCV_logit.best_estimator_\n",
    "\n",
    "# Train model on full train set\n",
    "best_logit.fit(X_train,y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_logit.predict(X_test)\n",
    "\n",
    "# Compute accuracy, precision, recall, F1\n",
    "print(f'(GridSearchCV-tuned model) Accuracy score = {accuracy_score(y_test,y_pred):.4f}')\n",
    "print(f'(GridSearchCV-tuned model) F1 score = {f1_score(y_test,y_pred):.4f}')\n",
    "print(f'(GridSearchCV-tuned model) Precision score = {precision_score(y_test,y_pred):.4f}')\n",
    "print(f'(GridSearchCV-tuned model) Recall score = {recall_score(y_test,y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0231c3a",
   "metadata": {},
   "source": [
    "## XGradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc0d2f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Initial 10-fold cross-validation) accuracy = 0.8722\n",
      "(Initial 10-fold cross-validation) f1 = 0.0512\n",
      "(Initial 10-fold cross-validation) precision = 0.3721\n",
      "(Initial 10-fold cross-validation) recall = 0.0275\n"
     ]
    }
   ],
   "source": [
    "# Initial results\n",
    "XGB = XGBClassifier(eval_metric='error')\n",
    "\n",
    "# Cross validation\n",
    "results = cross_validate(XGB,X=X_train,y=y_train,scoring=scores,cv=10)\n",
    "\n",
    "d_XGB_initial = {}\n",
    "\n",
    "for i in range(4):\n",
    "    score = scores[i]\n",
    "    d_XGB_initial[score] = np.mean(results['test_' +score])\n",
    "    print(f'(Initial 10-fold cross-validation) {score} = {d_XGB_initial[score]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tunning\n",
    "\n",
    "# Get hyperparameter options\n",
    "parameters = {\n",
    "    'n_estimators' : [100, 250, 500, 750, 1000], \n",
    "    'max_depth' : [3, 5, 7, 10, 12, 15, 17, 20, 25],\n",
    "    'learning_rate' : [0.05, 0.1, 0.15, 0.2, 0.25, 0.30],\n",
    "    'gamma' : [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'min_child_weight' : [1, 3, 5, 7],\n",
    "    'colsample_bytree' : [0.3, 0.4, 0.5, 0.7],\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "XGB = XGBClassifier(eval_metric='error')\n",
    "\n",
    "# Use gridsearch to determine the best model\n",
    "model_GSCV_XGboost = GridSearchCV(XGB,parameters,scoring=scores,cv=5,refit='f1')\n",
    "\n",
    "# fit\n",
    "model_GSCV_XGboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd30a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best parameters\n",
    "best_params = model_GSCV_XGboost.best_params_\n",
    "\n",
    "for key, value in best_params.items():\n",
    "    print(f'{key} =  {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_XGboost = model_GSCV_XGboost.best_estimator_\n",
    "\n",
    "# Train model on full train set\n",
    "best_XGboost.fit(X_train,y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_XGboost.predict(X_test)\n",
    "\n",
    "# Compute accuracy, precision, recall, F1\n",
    "print(f'(GridSearchCV-tuned model) Accuracy score = {accuracy_score(y_test,y_pred):.4f}')\n",
    "print(f'(GridSearchCV-tuned model) F1 score = {f1_score(y_test,y_pred):.4f}')\n",
    "print(f'(GridSearchCV-tuned model) Precision score = {precision_score(y_test,y_pred):.4f}')\n",
    "print(f'(GridSearchCV-tuned model) Recall score = {recall_score(y_test,y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239593a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
