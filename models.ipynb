{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a99830-db79-466e-8624-523bcea20094",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "207df8e0-e89d-4792-b668-3e89e8eff44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SK learn stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8272604-3e21-4908-a646-96822ec00a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success                                int64\n",
       "num_degs_finished_by_curr_ceo        float64\n",
       "max_number_founded_by_one_founder    float64\n",
       "avg_num_degs_finished_by_founders      int64\n",
       "at_least_one_veteran_founder           int64\n",
       "years_between_degree_founding          int64\n",
       "years_between_first_curr_founding      int64\n",
       "Advertising                            int64\n",
       "Apps                                   int64\n",
       "Commerce and Shopping                  int64\n",
       "Community and Lifestyle                int64\n",
       "Consumer Electronics                   int64\n",
       "Content and Publishing                 int64\n",
       "Data and Analytics                     int64\n",
       "Design                                 int64\n",
       "Education                              int64\n",
       "Financial Services                     int64\n",
       "Hardware                               int64\n",
       "Health Care                            int64\n",
       "Information Technology                 int64\n",
       "Internet Services                      int64\n",
       "Manufacturing                          int64\n",
       "Media and Entertainment                int64\n",
       "Mobile                                 int64\n",
       "Other                                  int64\n",
       "Professional Services                  int64\n",
       "Real Estate                            int64\n",
       "Sales and Marketing                    int64\n",
       "Science and Engineering                int64\n",
       "Software                               int64\n",
       "Video                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First import the data\n",
    "dataset =  pd.read_csv('finished_data/finished_data.csv').drop(columns=['Unnamed: 0'])\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a6a52-8118-4709-9759-92af93e3420e",
   "metadata": {},
   "source": [
    "## Final data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8dede615-10c4-46cd-98b3-0cd8f3f4c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a dataset of 67334 observations\n",
      "Out of that number, we have 8443 successful companies which accounts for a 12.54% of all observations\n",
      "Out of that number, we have 58891 failed companies which accounts for a 87.46% of all observations\n"
     ]
    }
   ],
   "source": [
    "success = dataset['success'].sum()\n",
    "failure = dataset['success'].count() - success\n",
    "\n",
    "print(f'We have a dataset of {success + failure} observations')\n",
    "print(f'Out of that number, we have {success} successful companies which accounts for a {success/(success + failure)*100:.2f}% of all observations')\n",
    "print(f'Out of that number, we have {failure} failed companies which accounts for a {failure/(success + failure)*100:.2f}% of all observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a1c9e2-5c4b-493c-90af-ad5b69d8c439",
   "metadata": {},
   "source": [
    "As we see there is a massive class imbalance.\n",
    "\n",
    "- Bootstrapping ???\n",
    "- Not bootstrapping ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "10fcb953-dcaa-4e1f-8e64-48440cba455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['success'])\n",
    "y = dataset['success']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8,random_state=109,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52985afb-b27f-4f06-af8a-dd349226e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X_train dataset is (53867, 30)\n",
      "The size of y_train dataset is (53867,)\n",
      "The size of X_test dataset is (13467, 30)\n",
      "The size of y_test dataset is (13467,)\n"
     ]
    }
   ],
   "source": [
    "print(f'The size of X_train dataset is {X_train.shape}')\n",
    "print(f'The size of y_train dataset is {y_train.shape}')\n",
    "print(f'The size of X_test dataset is {X_test.shape}')\n",
    "print(f'The size of y_test dataset is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac867c4-fd05-4dec-a9e4-28b09d548f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant scores\n",
    "scores = ['accuracy','f1','precision','recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ccdef-e461-4435-a140-6b937657b3a4",
   "metadata": {},
   "source": [
    "## Majority classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2ffdddd-4cb5-4250-a35d-a5e4afd3b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7706db77-306a-4ef2-9e70-e9c097b581e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuricy, precision, recall, F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc02857-e87b-4c4c-93a7-6fe88c33aa8f",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "82855d19-91d9-4f15-9ddd-b0fbdfc3208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b94a78e7-3b7d-44e1-a86d-cac0450f11a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Initial 10-fold cross-validation) accuracy = 0.8738\n",
      "(Initial 10-fold cross-validation) f1 = 0.0153\n",
      "(Initial 10-fold cross-validation) precision = 0.3554\n",
      "(Initial 10-fold cross-validation) recall = 0.0078\n"
     ]
    }
   ],
   "source": [
    "# Initial results\n",
    "logit = LogisticRegression(penalty='none',max_iter=100*10000,solver='saga')\n",
    "\n",
    "# Cross validation\n",
    "results = cross_validate(logit,X=X_train_scaled,y=y_train,scoring=scores,cv=10)\n",
    "\n",
    "d_logit_initial = {}\n",
    "\n",
    "for i in range(4):\n",
    "    score = scores[i]\n",
    "    d_logit_initial[score] = np.mean(results['test_' +score])\n",
    "    print(f'(Initial 10-fold cross-validation) {score} = {d_logit_initial[score]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7af9e-2a39-4f68-8333-7a1ba66ba665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tunning\n",
    "\n",
    "# Get hyperparameter options\n",
    "parameters = {\n",
    "    'penalty':['none','l1','l2'], \n",
    "    'C':[0.0001, 0.001, 0.01, 0.1, 0.5, 10, 50, 100, 1000]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "logit = LogisticRegression(max_iter=100*10000,solver='saga')\n",
    "\n",
    "# Use gridsearch to determine the best model\n",
    "model_GSCV = GridSearchCV(logit,parameters,scoring=scores,cv=10,refit=False)\n",
    "\n",
    "# fit\n",
    "model_GSCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b3d3d-a5bc-4a41-b31e-fc8557653586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8857bb5-2ec1-4e9b-8bce-4ff9a9b4af7c",
   "metadata": {},
   "source": [
    "## Feed-forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a62e522-0585-4473-bdab-1392eef33ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3fc76d3-523a-4fda-8a50-3f31a5fb3d18",
   "metadata": {},
   "source": [
    "## XGradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4634969-fb4f-4a1e-953e-21d953de542f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
